{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fully connected model [64->32->32->10], 10-class classification\n",
    "# using Sequential model\n",
    "\n",
    "K.clear_session()\n",
    "seq_model = models.Sequential()\n",
    "seq_model.add(layers.Dense(units=32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(units=32, activation='relu'))\n",
    "seq_model.add(layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# using functions API\n",
    "K.clear_session()\n",
    "\n",
    "input_x = Input(shape=(64,))\n",
    "x = layers.Dense(units=32, activation='relu')(input_x)\n",
    "x = layers.Dense(units=32, activation='relu')(x)\n",
    "output = layers.Dense(units=10, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=input_x, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 104.2670 - acc: 0.1200\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 103.7380 - acc: 0.1150\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 103.6353 - acc: 0.1060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 103.5794 - acc: 0.1240\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 97us/step - loss: 103.5444 - acc: 0.1160\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: 103.5186 - acc: 0.1210\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 105us/step - loss: 103.4905 - acc: 0.1240\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 112us/step - loss: 103.4637 - acc: 0.1240\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 131us/step - loss: 103.4486 - acc: 0.1220\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 163us/step - loss: 103.4280 - acc: 0.1340\n",
      "1000/1000 [==============================] - 0s 284us/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['acc'])\n",
    "\n",
    "x = np.random.random((1000, 64))\n",
    "y = np.random.randint(low=0, high=10, size=(1000, 10))\n",
    "\n",
    "model.fit(x, y, epochs=10, batch_size=128)\n",
    "\n",
    "score = model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[103.39110675048828, 0.148]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-input models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 32)     320000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           8320        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32)           8320        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 500)          32500       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 689,140\n",
      "Trainable params: 689,140\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_vocab_size = 10000\n",
    "question_vocab_size = 10000\n",
    "answer_vocab_size = 500\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "text_input = Input(shape=(None,), dtype=np.int32, name='text')\n",
    "text_emb = layers.Embedding(input_dim=text_vocab_size, output_dim=32)(text_input)\n",
    "text_lstm = layers.LSTM(units=32, return_sequences=False)(text_emb)\n",
    "\n",
    "question_input = Input(shape=(None,), dtype=np.int32, name='question')\n",
    "question_emb = layers.Embedding(input_dim=question_vocab_size, output_dim=32)(question_input)\n",
    "question_lstm = layers.LSTM(units=32, return_sequences=False)(question_emb)\n",
    "\n",
    "combined_input = layers.concatenate([text_lstm, question_lstm], axis=-1)\n",
    "output_vec = layers.Dense(units=answer_vocab_size, activation='softmax')(combined_input)\n",
    "\n",
    "model = models.Model(inputs=[text_input, question_input], outputs=output_vec)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy data\n",
    "n_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "x_texts = np.random.randint(1, text_vocab_size, size=(n_samples, max_length))\n",
    "x_questions = np.random.randint(1, question_vocab_size, size=(n_samples, max_length))\n",
    "y_answers = np.random.randint(0, 1, size=(n_samples, answer_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4ff078f28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_texts, x_questions], y_answers, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5005f37b8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit({'text':x_texts, 'question':x_questions}, y_answers, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-output models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 64)     81984       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 64)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 128)    41088       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 128)    82048       conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, None, 128)    0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    164096      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 256)    327936      conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 5)            645         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,530,951\n",
      "Trainable params: 13,530,951\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "\n",
    "vocab_size = 50000\n",
    "num_income_groups = 5\n",
    "\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "posts_emb = layers.Embedding(input_dim=vocab_size, output_dim=256)(posts_input)\n",
    "\n",
    "x = layers.Conv1D(filters=64, kernel_size=5, activation='relu')(posts_emb)\n",
    "x = layers.MaxPool1D(pool_size=5)(x)\n",
    "\n",
    "x = layers.Conv1D(filters=128, kernel_size=5, activation='relu')(x)\n",
    "x = layers.Conv1D(filters=128, kernel_size=5, activation='relu')(x)\n",
    "x = layers.MaxPool1D(pool_size=5)(x)\n",
    "\n",
    "x = layers.Conv1D(filters=256, kernel_size=5, activation='relu')(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dense(units=128, activation='relu')(x)\n",
    "\n",
    "age_predictions = layers.Dense(units=1, activation=None, name='age')(x)\n",
    "income_predictions = layers.Dense(units=num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_predictions = layers.Dense(units=1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = models.Model(inputs=posts_input, \n",
    "                     outputs=[age_predictions, income_predictions, gender_predictions])\n",
    "\n",
    "model.compile(loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'], \n",
    "              loss_weights=[.25, 1., 10.], \n",
    "              optimizer='rmsprop')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inception modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "import keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, C = 256, 256, 3\n",
    "a, b, c, d = 8, 8, 8, 8\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "x = layers.Input(shape=(H, W, C))\n",
    "\n",
    "branch_a = layers.Conv2D(filters=a, kernel_size=1, strides=2, activation='relu')(x)\n",
    "\n",
    "branch_b = layers.Conv2D(filters=a, kernel_size=1, strides=2, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(filters=b, kernel_size=3, strides=1, activation='relu', padding='same')(branch_b)\n",
    "\n",
    "branch_c = layers.AvgPool2D(pool_size=(3, 3), strides=2)(x)\n",
    "branch_c = layers.Conv2D(filters=c, kernel_size=(3, 3), strides=1, activation='relu', padding='same')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(filters=d, kernel_size=1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(filters=d, kernel_size=3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(filters=d, kernel_size=3, activation='relu', strides=2, padding='same')(branch_d)\n",
    "\n",
    "#output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_1/Relu:0' shape=(?, 128, 128, 8) dtype=float32>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_3/Relu:0' shape=(?, 128, 128, 8) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_4/Relu:0' shape=(?, 127, 127, 8) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_7/Relu:0' shape=(?, 127, 127, 8) dtype=float32>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer weight sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "\n",
    "lstm = layers.LSTM(32)\n",
    "embed = layers.Embedding(input_dim=10000, output_dim=128)\n",
    "\n",
    "left_input = layers.Input(shape=(None,))\n",
    "left_output = lstm(embed(left_input))\n",
    "\n",
    "right_input = layers.Input(shape=(None,))\n",
    "right_output = lstm(embed(right_input))\n",
    "\n",
    "right_left_combine = layers.concatenate([right_output, left_output], axis=-1)\n",
    "\n",
    "prediction = layers.Dense(units=1, activation='sigmoid')(right_left_combine)\n",
    "\n",
    "model = models.Model(inputs=[right_input, left_input], outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1280000     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           20608       embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           lstm_1[1][0]                     \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            65          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,300,673\n",
      "Trainable params: 1,300,673\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "\n",
    "xception_base = applications.Xception(include_top=False, weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input = layers.Input(shape=(250, 250, 3), name='l_input')\n",
    "right_input = layers.Input(shape=(250, 250, 3), name='r_input')\n",
    "\n",
    "left_output = xception_base(left_input)\n",
    "right_output = xception_base(right_input)\n",
    "\n",
    "merged_feature = layers.concatenate([left_output, right_output], axis=-1)\n",
    "\n",
    "model = models.Model(inputs=[left_input, right_input], outputs=merged_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "l_input (InputLayer)            (None, 250, 250, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "r_input (InputLayer)            (None, 250, 250, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                multiple             20861480    l_input[0][0]                    \n",
      "                                                                 r_input[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 4096)   0           xception[1][0]                   \n",
      "                                                                 xception[2][0]                   \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earlystopping and modelcheckpoint callbacks\n",
    "\n",
    "callback_list = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=2\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='my_model.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss'\n",
    "    )\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.EarlyStopping at 0x28605631080>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.ModelCheckpoint at 0x28605631a20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceLROnPlateau calllback\n",
    "\n",
    "callback_list = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=.5, patience=5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.ReduceLROnPlateau at 0x2860565d978>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import keras.backend as K\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 2000\n",
    "max_len = 500\n",
    "emb_dim = 128\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Embedding(input_dim=max_words, output_dim=emb_dim, \n",
    "                           input_length=max_len, name='embed'))\n",
    "model.add(layers.Conv1D(32, kernel_size=7, activation='relu'))\n",
    "model.add(layers.MaxPool1D(pool_size=5))\n",
    "model.add(layers.Conv1D(32, kernel_size=7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "    TensorBoard(\n",
    "        embeddings_layer_names=['embed'],\n",
    "        log_dir='./my_log_dir', \n",
    "        histogram_freq=1, \n",
    "        embeddings_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 5s 237us/step - loss: 0.5274 - acc: 0.7171 - val_loss: 0.3567 - val_acc: 0.8440\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 4s 222us/step - loss: 0.3300 - acc: 0.8575 - val_loss: 0.3286 - val_acc: 0.8590\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 4s 225us/step - loss: 0.2846 - acc: 0.8835 - val_loss: 0.3664 - val_acc: 0.8446\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 5s 225us/step - loss: 0.2487 - acc: 0.9003 - val_loss: 0.3172 - val_acc: 0.8666\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 4s 225us/step - loss: 0.2171 - acc: 0.9154 - val_loss: 0.3948 - val_acc: 0.8382\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 4s 224us/step - loss: 0.1842 - acc: 0.9322 - val_loss: 0.3424 - val_acc: 0.8664\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 4s 221us/step - loss: 0.1531 - acc: 0.9461 - val_loss: 0.3956 - val_acc: 0.8488\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 4s 223us/step - loss: 0.1214 - acc: 0.9601 - val_loss: 0.4562 - val_acc: 0.8402\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 4s 225us/step - loss: 0.0932 - acc: 0.9718 - val_loss: 0.4693 - val_acc: 0.8496\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 4s 219us/step - loss: 0.0680 - acc: 0.9810 - val_loss: 0.4274 - val_acc: 0.8630\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=10, \n",
    "                    batch_size=128, \n",
    "                    validation_split=0.2, \n",
    "                    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1860\u001b[0m                 \u001b[0mshell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1861\u001b[1;33m                 stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n\u001b[0m\u001b[0;32m   1862\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[0;32m    675\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    677\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    956\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    958\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1866\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1867\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot.exe\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-93da5b8388dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \"\"\"\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     32\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depthwise separable convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_1 (Separabl (None, 62, 62, 32)        155       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 60, 60, 64)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 28, 28, 64)        4736      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_4 (Separabl (None, 26, 26, 128)       8896      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_5 (Separabl (None, 11, 11, 64)        9408      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_6 (Separabl (None, 9, 9, 128)         8896      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 38,949\n",
      "Trainable params: 38,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "H, W, C = 64, 64, 3\n",
    "n_classes = 10\n",
    "\n",
    "m.add(layers.SeparableConv2D(filters=32, kernel_size=3, activation='relu', input_shape=(H,W,C)))\n",
    "m.add(layers.SeparableConv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "m.add(layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "m.add(layers.SeparableConv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "m.add(layers.SeparableConv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "m.add(layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "m.add(layers.SeparableConv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "m.add(layers.SeparableConv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "m.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "m.add(layers.Dense(32, activation='relu'))\n",
    "m.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "m.summary()\n",
    "\n",
    "m.compile(loss='categorical_crossentropy', \n",
    "          optimizer='rmsprop', \n",
    "          metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_learning]",
   "language": "python",
   "name": "conda-env-deep_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
